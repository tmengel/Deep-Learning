{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 14:13:59.996682: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-12 14:14:01.548352: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/tmengel/root/lib\n",
      "2023-05-12 14:14:01.548588: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-05-12 14:14:04.229136: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/tmengel/root/lib\n",
      "2023-05-12 14:14:04.229678: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/tmengel/root/lib\n",
      "2023-05-12 14:14:04.229704: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pulsenet as pn\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# modelfiles #######################\n",
    "# direct transfer\n",
    "transfer_model = \"models/transfer_model.h5\"\n",
    "# direct transfer with fine tuning\n",
    "fine_tuned_model = \"models/fine_tuned_model.h5\"\n",
    "# long transfer\n",
    "transfer_model_trace_transfer = \"models/transfer_trace_transfer_model.h5\"\n",
    "# long transfer with fine tuning\n",
    "fine_tuned_trace_transfer_model = \"models/fine_tuned_trace_transfer_model.h5\"\n",
    "# control\n",
    "control_model = \"models/control_model.h5\"\n",
    "# sequential\n",
    "sequential_model =\"models/sequential_training_model.h5\"\n",
    "\n",
    "input = layers.Input(shape=(1, 300))  # Returns a placeholder tensor\n",
    "classifer_feature_vec = pn.TraceClassifierBase(name = \"classifier_base\")(input)\n",
    "discriminator_feature_vec = pn.TraceDiscriminatorBase(name = \"discriminator_base\")(input)\n",
    "trace_output = pn.TraceClassifierDiscriminatorHead(name = \"transfer_head\")([discriminator_feature_vec, classifer_feature_vec])\n",
    "phase_output = pn.TracePhaseRegressor(name=\"phase_regressor\")(trace_output)\n",
    "amplitude_output = pn.TraceAmplitudeRegressor(name =\"amplitude_regressor\")(trace_output)\n",
    "classifier_output = pn.TraceClassifierHead(name=\"classifier_head\")(classifer_feature_vec)\n",
    "\n",
    "control = models.Model(inputs=input, outputs=[trace_output, phase_output, amplitude_output])\n",
    "control.load_weights(control_model)\n",
    "\n",
    "transfer_direct = models.Model(inputs=input, outputs=[trace_output, phase_output, amplitude_output])\n",
    "transfer_direct.load_weights(fine_tuned_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 437552 samples: 49.96594690459648 % pileup, 50.03405309540352 % no pileup\n"
     ]
    }
   ],
   "source": [
    "filename = \"ysoTracesNoPileup.root\"\n",
    "x_trace, y_trace, y_phase, y_amp =  pn.CreateData(filename, pileup_split=0.5, phase_min=0, phase_max=20, amplitude_min=0.5, amplitude_max=1.5)\n",
    "y_pileup_onehot = pn.EncodePileup(y_phase)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 14:27:53.400600: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 525062400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13674/13674 [==============================] - 349s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 14:33:58.482199: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1050124800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/tmengel/DeepLearning/Deep-Learning/finalProject/testing.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tmengel/DeepLearning/Deep-Learning/finalProject/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# predict on data\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tmengel/DeepLearning/Deep-Learning/finalProject/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m control_trace_pred, control_phase_pred, control_amp_pred \u001b[39m=\u001b[39m control\u001b[39m.\u001b[39;49mpredict(x_trace)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tmengel/DeepLearning/Deep-Learning/finalProject/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m transfer_trace_pred, transfer_phase_pred, transfer_amp_pred \u001b[39m=\u001b[39m transfer_direct\u001b[39m.\u001b[39mpredict(x_trace)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py:2394\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2391\u001b[0m \u001b[39mif\u001b[39;00m original_pss_strategy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2392\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_distribution_strategy \u001b[39m=\u001b[39m original_pss_strategy\n\u001b[0;32m-> 2394\u001b[0m \u001b[39mreturn\u001b[39;00m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(all_outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/tf_utils.py:665\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[39mreturn\u001b[39;00m t\n\u001b[1;32m    663\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[0;32m--> 665\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/tf_utils.py:658\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    656\u001b[0m     \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    657\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 658\u001b[0m         t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    659\u001b[0m     \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[1;32m    660\u001b[0m     \u001b[39m# as-is.\u001b[39;00m\n\u001b[1;32m    661\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1156\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m   1155\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 1156\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39;49mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# predict on data\n",
    "control_trace_pred, control_phase_pred, control_amp_pred = control.predict(x_trace)\n",
    "transfer_trace_pred, transfer_phase_pred, transfer_amp_pred = transfer_direct.predict(x_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "control_loss = control.evaluate(x_trace, [y_trace, y_phase, y_amp])\n",
    "transfer_loss = transfer_direct.evaluate(x_trace, [y_trace, y_phase, y_amp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calulate residuals\n",
    "phase_fine_tuned_residuals = phase_pred_fine_tuned - y_phase\n",
    "phase_transfer_learned_residuals = phase_pred_transfer_learned - y_phase\n",
    "phase_initial_residuals = phase_pred_initial - y_phase\n",
    "\n",
    "amp_fine_tuned_residuals = amp_pred_fine_tuned - y_amp\n",
    "amp_transfer_learned_residuals = amp_pred_transfer_learned - y_amp\n",
    "amp_initial_residuals = amp_pred_initial - y_amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "pred_class_fine_tuned = pileup_pred_fine_tuned[:,0] # pileup classifier output is (1,0) if pileup, (0,1) if not pileup\n",
    "pred_class_transfer_learned = pileup_pred_transfer_learned[:,0]\n",
    "pred_class_initial = pileup_pred_initial[:,0]\n",
    "truth_class = y_pileup_onehot[:,0] # one hot encoded truth is (1,0) if pileup, (0,1) if not pileup\n",
    "\n",
    "ft_fpr, ft_tpr, ft_thresholds = roc_curve(truth_class, pred_class_fine_tuned)\n",
    "tl_fpr, tl_tpr, tl_thresholds = roc_curve(truth_class, pred_class_transfer_learned)\n",
    "in_fpr, in_tpr, in_thresholds = roc_curve(truth_class, pred_class_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(ft_fpr, ft_tpr, label=\"Fine Tuned\")\n",
    "plt.plot(tl_fpr, tl_tpr, label=\"Transfer Learned\")\n",
    "plt.plot(in_fpr, in_tpr, label=\"Initial\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--', label=\"No Skill\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "phase_bins = np.linspace(0,20,20)\n",
    "amp_bins = np.linspace(0.5,1.5,20)\n",
    "\n",
    "pdf = pd.DataFrame({\"Phase\":y_phase[:,0], \"Phase Fine Tuned\":phase_pred_fine_tuned[:,0], \"Phase Transfer Learned\":phase_pred_transfer_learned[:,0], \"Phase Initial\":phase_pred_initial[:,0]})\n",
    "adf = pd.DataFrame({\"Amplitude\":y_amp[:,0], \"Amplitude Fine Tuned\":amp_pred_fine_tuned[:,0], \"Amplitude Transfer Learned\":amp_pred_transfer_learned[:,0], \"Amplitude Initial\":amp_pred_initial[:,0]})\n",
    "\n",
    "p_ft_sigma = []\n",
    "p_tl_sigma = []\n",
    "p_in_sigma = []\n",
    "a_ft_sigma = []\n",
    "a_tl_sigma = []\n",
    "a_in_sigma = []\n",
    "\n",
    "\n",
    "for i in range(0,19):\n",
    "    pdf_bin = pdf[(pdf[\"Phase\"] > phase_bins[i]) & (pdf[\"Phase\"] < phase_bins[i+1])].copy()\n",
    "    adf_bin = adf[(adf[\"Amplitude\"] > amp_bins[i]) & (adf[\"Amplitude\"] < amp_bins[i+1])].copy()\n",
    "    p_ft_sigma.append(pdf_bin[\"Phase Fine Tuned\"].std())\n",
    "    p_tl_sigma.append(pdf_bin[\"Phase Transfer Learned\"].std())\n",
    "    p_in_sigma.append(pdf_bin[\"Phase Initial\"].std())\n",
    "    a_ft_sigma.append(adf_bin[\"Amplitude Fine Tuned\"].std())\n",
    "    a_tl_sigma.append(adf_bin[\"Amplitude Transfer Learned\"].std())\n",
    "    a_in_sigma.append(adf_bin[\"Amplitude Initial\"].std())   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(phase_bins[:-1], p_ft_sigma, label=\"Fine Tuned\")\n",
    "plt.plot(phase_bins[:-1], p_tl_sigma, label=\"Transfer Learned\")\n",
    "plt.plot(phase_bins[:-1], p_in_sigma, label=\"Initial\")\n",
    "plt.xlabel(r\"Phase $\\phi$ (ns)\")\n",
    "plt.ylabel(r\"$\\sigma(\\delta\\phi)$\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(amp_bins[:-1], a_ft_sigma, label=\"Fine Tuned\")\n",
    "plt.plot(amp_bins[:-1], a_tl_sigma, label=\"Transfer Learned\")\n",
    "plt.plot(amp_bins[:-1], a_in_sigma, label=\"Initial\")\n",
    "plt.xlabel(r\"Amplitude $A$ (mV)\")\n",
    "plt.ylabel(r\"$\\sigma(\\delta A)$\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_divergence(p, q):\n",
    "    return np.sum(np.where(p != 0, p * np.log(p / q), 0))\n",
    "\n",
    "ft_kl0 = KL_divergence(trace_pred_fine_tuned[:,0], y_trace[:,0])\n",
    "tl_kl0= KL_divergence(trace_pred_transfer_learned[:,0], y_trace[:,0])   \n",
    "in_kl0 = KL_divergence(trace_pred_initial[:,0], y_trace[:,0])\n",
    "\n",
    "ft_kl1 = KL_divergence(phase_pred_fine_tuned[:,0], y_phase[:,0])\n",
    "tl_kl1 = KL_divergence(phase_pred_transfer_learned[:,0], y_phase[:,0])\n",
    "in_kl1 = KL_divergence(phase_pred_initial[:,0], y_phase[:,0])\n",
    "\n",
    "ft_kl = np.concatenate((ft_kl0, ft_kl1), axis=0)\n",
    "tl_kl = np.concatenate((tl_kl0, tl_kl1), axis=0)\n",
    "in_kl = np.concatenate((in_kl0, in_kl1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ft_kl, bins=100, label=\"Fine Tuned\", alpha=0.5, density=True)\n",
    "plt.hist(tl_kl, bins=100, label=\"Transfer Learned\", alpha=0.5, density=True)\n",
    "plt.hist(in_kl, bins=100, label=\"Initial\", alpha=0.5, density=True)\n",
    "plt.xlabel(\"KL Divergence\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
