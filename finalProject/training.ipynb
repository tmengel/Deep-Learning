{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Training__\n",
    "\n",
    "* ✅ **Sub-Modules**\n",
    "    * ✅ Discriminator\n",
    "    * ✅ Classifier\n",
    "    * ✅ Phase Regressor\n",
    "    * ✅ Amplitude Regressor\n",
    "\n",
    "\n",
    "* ✅ **Transfer Learning**\n",
    "    * ✅ Transfer 1 (Direct) \n",
    "        * ✅ Train Transfer Head on Trace, Phase and Amplitude\n",
    "        * ✅ Fine-Tune whole Model\n",
    "    * ✅ Transfer 2 (Long) \n",
    "        * ✅ Train Transfer Head on Trace\n",
    "        * ✅ Fine Tune Phase\n",
    "        * ✅ Fine Tune Amplitude\n",
    "\n",
    "\n",
    "* ✅ **Sequential Trianing** \n",
    "    * ✅ Train whole model on trace\n",
    "    * ✅ Train whole model on phase\n",
    "    * ✅ Train whole model on amplitude\n",
    "\n",
    "\n",
    "* ✅ **Control Training** \n",
    "    * ✅ Train whole model on trace, phase and amplitude\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in Colab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 17:17:57.194679: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-12 17:17:57.378382: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/tmengel/root/lib\n",
      "2023-05-12 17:17:57.378413: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-05-12 17:17:58.695620: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/tmengel/root/lib\n",
      "2023-05-12 17:17:58.696091: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/tmengel/root/lib\n",
      "2023-05-12 17:17:58.696131: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')   \n",
    "    RUNNING_IN_COLAB = True\n",
    "    \n",
    "except:\n",
    "    print(\"Not in Colab\")\n",
    "    RUNNING_IN_COLAB = False\n",
    "    \n",
    "if RUNNING_IN_COLAB:\n",
    "    print(\"Running in Colab\")\n",
    "    #pull git repo and install requirements\n",
    "    !git clone https://github.com/tmengel/Deep-Learning.git\n",
    "    %cd Deep-Learning/finalProject\n",
    "    %pip install uproot\n",
    "    %pip install pandas\n",
    "\n",
    "import pulsenet as pn\n",
    "import pandas as pd  \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"training_traces.root\"\n",
    "if RUNNING_IN_COLAB:\n",
    "    filename = \"/content/drive/MyDrive/DeepLearningFinalProject/ysoTracesWithPileup.root\"\n",
    "    \n",
    "def GetData():\n",
    "    x_trace, y_trace, y_phase, y_amp = pn.CreateData(filename, pileup_split=0.5, phase_min=0.1, phase_max=20, amplitude_min=0.5, amplitude_max=1.5)\n",
    "    y_pileup = pn.EncodePileup(y_phase)\n",
    "    return x_trace, y_trace, y_phase, y_amp, y_pileup\n",
    "\n",
    "epochs = 500\n",
    "batchsize = 128 \n",
    "validation_split = 0.2\n",
    "\n",
    "def SaveModel(disriminator_base, classifier_base, phase, amplitude, tracenet, modelfile):\n",
    "    \n",
    "    input = layers.Input(shape=(1, 300))  # Returns a placeholder tensor\n",
    "    classifer_feature_vec = pn.TraceClassifierBase(name = \"classifier_base\")(input)\n",
    "    discriminator_feature_vec = pn.TraceDiscriminatorBase(name = \"discriminator_base\")(input)\n",
    "    trace_output = pn.TraceClassifierDiscriminatorHead(name = \"tracenet\")([discriminator_feature_vec, classifer_feature_vec])\n",
    "    phase_output = pn.TracePhaseRegressor(name=\"phase\")(trace_output)\n",
    "    amplitude_output = pn.TraceAmplitudeRegressor(name =\"amplitude\")(trace_output)\n",
    "    \n",
    "    model = models.Model(inputs=input, outputs=[trace_output, phase_output, amplitude_output])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "    model_names = [model.layers[i].name for i in range(len(model.layers))]\n",
    "    # load weights\n",
    "    model.layers[model_names.index(\"discriminator_base\")].load_weights(disriminator_base)\n",
    "    model.layers[model_names.index(\"classifier_base\")].load_weights(classifier_base)\n",
    "    model.layers[model_names.index(\"phase\")].load_weights(phase)\n",
    "    model.layers[model_names.index(\"amplitude\")].load_weights(amplitude)\n",
    "    model.layers[model_names.index(\"tracenet\")].load_weights(tracenet)\n",
    "    \n",
    "    # print summary\n",
    "    model.summary()\n",
    "    \n",
    "    # save model\n",
    "    model.save(modelfile)\n",
    "    \n",
    "    if RUNNING_IN_COLAB:\n",
    "        !cp models /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sub modules training**\n",
    "- ✅ Discrminator\n",
    "- ✅ Classifier\n",
    "- ✅ Phase \n",
    "- ✅ Amplitude"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Discriminator__ (Done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Data\n",
    "x_trace, y_trace, y_phase, y_amp, y_pileup = GetData()\n",
    "# Create model\n",
    "model = keras.Sequential([\n",
    "    pn.TraceDiscriminatorBase(name=\"discriminator_base\"),\n",
    "    pn.TraceDiscriminatorHead(name=\"discriminator_head\")\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(x_trace, y_trace, epochs=epochs, batch_size=batchsize, validation_split=validation_split, verbose=1)\n",
    "model.layers[0].save_weights('weights/individual_discriminator_base_weights.h5')\n",
    "model.layers[1].save_weights('weights/individual_discriminator_head_weights.h5')\n",
    "# Save history\n",
    "pd.DataFrame(history.history, index=history.epoch, columns=history.history.keys()).to_hdf('history/individual_discriminator_history.h5', key=\"hist\")\n",
    "\n",
    "if RUNNING_IN_COLAB:\n",
    "    !cp -rf weights /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "    !cp -rf history /content/drive/MyDrive/DeepLearningFinalProject/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Classifier__ (Done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trace, y_trace, y_phase, y_amp, y_pileup = GetData()\n",
    "# Create model\n",
    "model = keras.Sequential([\n",
    "    pn.TraceClassifierBase(name=\"classifier_base\"),\n",
    "    pn.TraceClassifierHead(name=\"classifier_head\")\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(x_trace, y_pileup, epochs=epochs, batch_size=batchsize, validation_split=validation_split, verbose=1)\n",
    "model.layers[0].save_weights('weights/individual_classifier_base_weights.h5')\n",
    "model.layers[1].save_weights('weights/individual_classifier_head_weights.h5')\n",
    "# Save history\n",
    "pd.DataFrame(history.history, index=history.epoch, columns=history.history.keys()).to_hdf('history/individual_classifier_history.h5', key=\"hist\")\n",
    "\n",
    "if RUNNING_IN_COLAB:\n",
    "    !cp -rf weights /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "    !cp -rf history /content/drive/MyDrive/DeepLearningFinalProject/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Amplitude__ (Done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trace, y_trace, y_phase, y_amp, y_pileup = GetData()\n",
    "# Create model\n",
    "model = keras.Sequential([\n",
    "    pn.TraceAmplitudeRegressor(name = \"amplitude\")\n",
    "])\n",
    "model.compile(optimizer='adam', loss=\"mse\", metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(x_trace, y_amp, epochs=epochs, batch_size=batchsize, validation_split=validation_split, verbose=1)\n",
    "model.layers[0].save_weights('weights/individual_amplitude_weights.h5')\n",
    "pd.DataFrame(history.history, index=history.epoch, columns=history.history.keys()).to_hdf('history/individual_amplitude_history.h5', key=\"hist\")\n",
    "\n",
    "if RUNNING_IN_COLAB:\n",
    "    !cp -rf weights /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "    !cp -rf history /content/drive/MyDrive/DeepLearningFinalProject/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Phase__ (Done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trace, y_trace, y_phase, y_amp, y_pileup = GetData()\n",
    "# Create model\n",
    "model = keras.Sequential([\n",
    "    pn.TracePhaseRegressor(name = \"phase\")\n",
    "])\n",
    "model.compile(optimizer='adam', loss=\"mse\", metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(x_trace, y_phase, epochs=epochs, batch_size=batchsize, validation_split=validation_split, verbose=1)\n",
    "model.layers[0].save_weights('weights/individual_phase_weights.h5')\n",
    "pd.DataFrame(history.history, index=history.epoch, columns=history.history.keys()).to_hdf('history/individual_phase_history.h5', key=\"hist\")\n",
    "\n",
    "if RUNNING_IN_COLAB:\n",
    "    !cp -rf weights /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "    !cp -rf history /content/drive/MyDrive/DeepLearningFinalProject/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **__Transfer Learning__**\n",
    "_____\n",
    "* ✅ Transfer 1 (Full)\n",
    "* ✅ Transfer 2 (Trace) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = layers.Input(shape=(1, 300))  # Returns a placeholder tensor\n",
    "classifer_feature_vec = pn.TraceClassifierBase(name = \"classifier_base\")(input)\n",
    "discriminator_feature_vec = pn.TraceDiscriminatorBase(name = \"discriminator_base\")(input)\n",
    "trace_output = pn.TraceClassifierDiscriminatorHead(name = \"tracenet\")([discriminator_feature_vec, classifer_feature_vec])\n",
    "phase_output = pn.TracePhaseRegressor(name=\"phase\")(trace_output)\n",
    "amplitude_output = pn.TraceAmplitudeRegressor(name =\"amplitude\")(trace_output)\n",
    "classifier_output = pn.TraceClassifierHead(name=\"classifier_head\")(classifer_feature_vec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Transfer 1 (Direct)__ (Done)\n",
    "* ✅ Transfer trace, phase and classifier onto new head\n",
    "* ✅ Fine-tune model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trace, y_trace, y_phase, y_amp, y_pileup = GetData()\n",
    "# create model\n",
    "model = models.Model(inputs=input, outputs=[trace_output, phase_output, amplitude_output])\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "model_names = [model.layers[i].name for i in range(len(model.layers))]\n",
    "# load weights\n",
    "model.layers[model_names.index(\"discriminator_base\")].load_weights('weights/individual_discriminator_base_weights.h5')\n",
    "model.layers[model_names.index(\"classifier_base\")].load_weights('weights/individual_classifier_base_weights.h5')\n",
    "model.layers[model_names.index(\"phase\")].load_weights('weights/individual_phase_weights.h5')\n",
    "model.layers[model_names.index(\"amplitude\")].load_weights('weights/individual_amplitude_weights.h5')\n",
    "model.layers[model_names.index(\"discriminator_base\")].trainable = False\n",
    "model.layers[model_names.index(\"classifier_base\")].trainable = False\n",
    "model.layers[model_names.index(\"phase\")].trainable = False\n",
    "model.layers[model_names.index(\"amplitude\")].trainable = False                           \n",
    "# print summary\n",
    "model.summary()                                                         \n",
    "# Train Discriminator Head\n",
    "history = model.fit(x_trace, [y_trace, y_phase, y_amp], epochs=epochs, batch_size=batchsize, validation_split=validation_split, verbose=1)\n",
    "# save weights\n",
    "model.layers[model_names.index(\"tracenet\")].save_weights('weights/full_transfer_tracenet_weights.h5')\n",
    "# save model\n",
    "SaveModel(disciminator_base='weights/individual_discriminator_base_weights.h5',\n",
    "          classifier_base='weights/individual_classifier_base_weights.h5',\n",
    "          phase='weights/individual_phase_weights.h5',\n",
    "          amplitude='weights/individual_amplitude_weights.h5',\n",
    "          tracenet='weights/full_transfer_tracenet_weights.h5',\n",
    "          modelfile='models/full_transfer_model.h5')\n",
    "# save history\n",
    "pd.DataFrame(history.history, index=history.epoch, columns=history.history.keys()).to_hdf('history/full_transfer_history.h5', key=\"hist\")\n",
    "if RUNNING_IN_COLAB:\n",
    "    !cp -rf weights /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "    !cp -rf history /content/drive/MyDrive/DeepLearningFinalProject/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trace, y_trace, y_phase, y_amp, y_pileup = GetData()\n",
    "# create model\n",
    "model = models.Model(inputs=input, outputs=[trace_output, phase_output, amplitude_output])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=['mse', 'mse', 'mse'], metrics=['accuracy'])\n",
    "model_names = [model.layers[i].name for i in range(len(model.layers))]\n",
    "# load weights\n",
    "model.layers[model_names.index(\"discriminator_base\")].load_weights('weights/individual_discriminator_base_weights.h5')\n",
    "model.layers[model_names.index(\"classifier_base\")].load_weights('weights/individual_classifier_base_weights.h5')\n",
    "model.layers[model_names.index(\"phase\")].load_weights('weights/individual_phase_weights.h5')\n",
    "model.layers[model_names.index(\"amplitude\")].load_weights('weights/individual_amplitude_weights.h5')\n",
    "model.layers[model_names.index(\"tracenet\")].load_weights('weights/full_transfer_tracenet_weights.h5')                \n",
    "# print summary\n",
    "model.summary()                                                         \n",
    "# Train Discriminator Head\n",
    "history = model.fit(x_trace, [y_trace, y_phase, y_amp], epochs=epochs, batch_size=batchsize, validation_split=validation_split, verbose=1)\n",
    "# save weights\n",
    "model.layers[model_names.index(\"discriminator_base\")].save_weights('weights/full_transfer_fine_tuned_discriminator_base_weights.h5')\n",
    "model.layers[model_names.index(\"classifier_base\")].save_weights('weights/full_transfer_fine_tuned_classifier_base_weights.h5')\n",
    "model.layers[model_names.index(\"phase\")].save_weights('weights/full_transfer_fine_tuned_phase_weights.h5')\n",
    "model.layers[model_names.index(\"amplitude\")].save_weights('weights/full_transfer_fine_tuned_amplitude_weights.h5')\n",
    "model.layers[model_names.index(\"tracenet\")].save_weights('weights/full_transfer_fine_tuned_tracenet_weights.h5')\n",
    "# save model\n",
    "SaveModel(disciminator_base= 'weights/full_transfer_fine_tuned_discriminator_base_weights.h5',\n",
    "          classifier_base= 'weights/full_transfer_fine_tuned_classifier_base_weights.h5',\n",
    "          phase= 'weights/full_transfer_fine_tuned_phase_weights.h5',\n",
    "          amplitude= 'weights/full_transfer_fine_tuned_amplitude_weights.h5',\n",
    "          tracenet= 'weights/full_transfer_fine_tuned_tracenet_weights.h5',\n",
    "          modelfile='models/full_transfer_fine_tuned_model.h5')\n",
    "# save history\n",
    "pd.DataFrame(history.history, index=history.epoch, columns=history.history.keys()).to_hdf('history/full_transfer_fine_tuning_history.h5', key=\"hist\")\n",
    "if RUNNING_IN_COLAB:\n",
    "    !cp -rf weights /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "    !cp -rf history /content/drive/MyDrive/DeepLearningFinalProject/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Transfer 2 (Long)__ (Done)\n",
    "* ✅ Transfer Trace onto head\n",
    "* ✅ Transfer amplitude and phase onto head\n",
    "* ✅ Fine tune\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfer Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trace, y_trace, y_phase, y_amp, y_pileup = GetData()\n",
    "epochs = 200\n",
    "# create model\n",
    "model = models.Model(inputs=input, outputs=trace_output)\n",
    "model.compile(optimizer='adam', loss=\"mse\", metrics=['accuracy'])\n",
    "model_names = [model.layers[i].name for i in range(len(model.layers))]\n",
    "# load weights\n",
    "model.layers[model_names.index(\"discriminator_base\")].load_weights('weights/individual_discriminator_base_weights.h5')\n",
    "model.layers[model_names.index(\"classifier_base\")].load_weights('weights/individual_classifier_base_weights.h5')\n",
    "# freeze layers\n",
    "model.layers[model_names.index(\"discriminator_base\")].trainable = False\n",
    "model.layers[model_names.index(\"classifier_base\")].trainable = False                         \n",
    "# print summary\n",
    "model.summary()                                                         \n",
    "# Train Discriminator Head\n",
    "history = model.fit(x_trace,y_trace, epochs=epochs, batch_size=batchsize, validation_split=validation_split, verbose=1)\n",
    "# save weights\n",
    "model.layers[model_names.index(\"tracenet\")].save_weights('weights/trace_transfer_tracenet_weights.h5')\n",
    "# save model\n",
    "SaveModel(disciminator_base='weights/individual_discriminator_base_weights.h5',\n",
    "            classifier_base='weights/individual_classifier_base_weights.h5',\n",
    "            phase='weights/individual_phase_weights.h5',\n",
    "            amplitude='weights/individual_amplitude_weights.h5',\n",
    "            tracenet='weights/trace_transfer_tracenet_weights.h5',\n",
    "            modelfile='models/trace_transfer_model.h5')\n",
    "\n",
    "# save history\n",
    "pd.DataFrame(history.history, index=history.epoch, columns=history.history.keys()).to_hdf('history/trace_transfer_history.h5', key=\"hist\")\n",
    "if RUNNING_IN_COLAB:\n",
    "    !cp -rf weights /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "    !cp -rf history /content/drive/MyDrive/DeepLearningFinalProject/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine Tune Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trace, y_trace, y_phase, y_amp, y_pileup = GetData()\n",
    "epochs = 200\n",
    "# create model\n",
    "model = models.Model(inputs=input, outputs=phase_output)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=\"mse\", metrics=['accuracy'])\n",
    "model_names = [model.layers[i].name for i in range(len(model.layers))]\n",
    "# load weights\n",
    "model.layers[model_names.index(\"discriminator_base\")].load_weights('weights/individual_discriminator_base_weights.h5')\n",
    "model.layers[model_names.index(\"classifier_base\")].load_weights('weights/individual_classifier_base_weights.h5')\n",
    "model.layers[model_names.index(\"phase\")].load_weights('weights/individual_phase_weights.h5')\n",
    "model.layers[model_names.index(\"tracenet\")].load_weights('weights/trace_transfer_tracenet_weights.h5')\n",
    "# freeze layers\n",
    "model.layers[model_names.index(\"discriminator_base\")].trainable = False\n",
    "model.layers[model_names.index(\"classifier_base\")].trainable = False\n",
    "model.layers[model_names.index(\"tracenet\")].trainable = False\n",
    "# print summary\n",
    "model.summary()                                                         \n",
    "# Train Discriminator Head\n",
    "history = model.fit(x_trace, y_phase, epochs=epochs, batch_size=batchsize, validation_split=validation_split, verbose=1)\n",
    "# save weights\n",
    "model.layers[model_names.index(\"phase\")].save_weights('weights/trace_transfer_fine_tuned_phase_weights.h5')\n",
    "# save history\n",
    "pd.DataFrame(history.history, index=history.epoch, columns=history.history.keys()).to_hdf('history/trace_transfer_phase_fine_tuning_history.h5', key=\"hist\")\n",
    "if RUNNING_IN_COLAB:\n",
    "    !cp -rf weights /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "    !cp -rf history /content/drive/MyDrive/DeepLearningFinalProject/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Fine Tune Amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trace, y_trace, y_phase, y_amp, y_pileup = GetData()\n",
    "epochs = 200\n",
    "# create model\n",
    "model = models.Model(inputs=input, outputs=amplitude_output)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=\"mse\", metrics=['accuracy'])\n",
    "model_names = [model.layers[i].name for i in range(len(model.layers))]\n",
    "# load weights\n",
    "model.layers[model_names.index(\"discriminator_base\")].load_weights('weights/individual_discriminator_base_weights.h5')\n",
    "model.layers[model_names.index(\"classifier_base\")].load_weights('weights/individual_classifier_base_weights.h5')\n",
    "model.layers[model_names.index(\"amplitude\")].load_weights('weights/individual_amplitude_weights.h5')\n",
    "model.layers[model_names.index(\"tracenet\")].load_weights('weights/trace_transfer_tracenet_weights.h5')\n",
    "# freeze layers\n",
    "model.layers[model_names.index(\"discriminator_base\")].trainable = False\n",
    "model.layers[model_names.index(\"classifier_base\")].trainable = False\n",
    "model.layers[model_names.index(\"tracenet\")].trainable = False\n",
    "# print summary\n",
    "model.summary()                                                         \n",
    "# Train Discriminator Head\n",
    "history = model.fit(x_trace, y_amp, epochs=epochs, batch_size=batchsize, validation_split=validation_split, verbose=1)\n",
    "# save weights\n",
    "model.layers[model_names.index(\"amplitude\")].save_weights('weights/trace_transfer_fine_tuned_amplitude_weights.h5')\n",
    "# save history\n",
    "pd.DataFrame(history.history, index=history.epoch, columns=history.history.keys()).to_hdf('history/trace_transfer_amplitude_fine_tuning_history.h5', key=\"hist\")\n",
    "if RUNNING_IN_COLAB:\n",
    "    !cp -rf weights /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "    !cp -rf history /content/drive/MyDrive/DeepLearningFinalProject/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveModel(disciminator_base='weights/individual_discriminator_base_weights.h5',\n",
    "            classifier_base='weights/individual_classifier_base_weights.h5',\n",
    "            phase='weights/trace_transfer_fine_tuned_phase_weights.h5',\n",
    "            amplitude='weights/trace_transfer_fine_tuned_amplitude_weights.h5',\n",
    "            tracenet='weights/trace_transfer_tracenet_weights.h5',\n",
    "            modelfile='models/trace_transfer_fine_tuned_model.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Control__\n",
    "* ✅ Train whole network at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trace, y_trace, y_phase, y_amp, y_pileup = GetData()\n",
    "epochs = 1000\n",
    "# create model\n",
    "model = models.Model(inputs=input, outputs=[trace_output, phase_output, amplitude_output])\n",
    "model.compile(optimizer=\"adam\",loss=\"mse\", metrics=['accuracy'])\n",
    "model_names = [model.layers[i].name for i in range(len(model.layers))]\n",
    "# print summary\n",
    "model.summary()\n",
    "# train control model\n",
    "history = model.fit(x_trace, [y_trace, y_phase, y_amp], epochs=epochs, batch_size=batchsize, validation_split=validation_split, verbose=1)\n",
    "# save weights\n",
    "model.layers[model_names.index(\"discriminator_base\")].save_weights('weights/control_discriminator_base_weights.h5')\n",
    "model.layers[model_names.index(\"classifier_base\")].save_weights('weights/control_classifier_base_weights.h5')\n",
    "model.layers[model_names.index(\"phase\")].save_weights('weights/control_phase_weights.h5')\n",
    "model.layers[model_names.index(\"amplitude\")].save_weights('weights/control_amplitude_weights.h5')\n",
    "model.layers[model_names.index(\"tracenet\")].save_weights('weights/control_tracenet_weights.h5')\n",
    "# save model\n",
    "SaveModel(disciminator_base='weights/control_discriminator_base_weights.h5',\n",
    "            classifier_base='weights/control_classifier_base_weights.h5',\n",
    "            phase='weights/control_phase_weights.h5',\n",
    "            amplitude='weights/control_amplitude_weights.h5',\n",
    "            tracenet='weights/control_tracenet_weights.h5',\n",
    "            modelfile='models/control_model.h5')\n",
    "\n",
    "# save history\n",
    "pd.DataFrame(history.history, index=history.epoch, columns=history.history.keys()).to_hdf('history/control_history.h5', key=\"hist\")\n",
    "if RUNNING_IN_COLAB:\n",
    "    !cp -rf weights /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "    !cp -rf history /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Sequential Training__\n",
    "* ✅ Train whole model on trace\n",
    "* ✅ Train whole model on phase\n",
    "* ✅ Train whole model on amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = layers.Input(shape=(1, 300))  # Returns a placeholder tensor\n",
    "discriminator_feature_vec = pn.TraceDiscriminatorBase(name = \"discriminator_base\")(input)\n",
    "trace_output = pn.TraceDiscriminatorHead(name = \"discriminator_head\")(discriminator_feature_vec)\n",
    "phase_output = pn.TracePhaseRegressor(name=\"phase\")(trace_output)\n",
    "amplitude_output = pn.TraceAmplitudeRegressor(name =\"amplitude\")(trace_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Train Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load new data\n",
    "epochs = 700\n",
    "x_trace, y_trace, y_phase, y_amp, y_pileup = GetData()\n",
    "\n",
    "# Train Discriminator\n",
    "# create model\n",
    "model = models.Model(inputs=input, outputs=trace_output)\n",
    "model.compile(optimizer=\"adam\", loss='mse', metrics=['accuracy'])\n",
    "model_names = [model.layers[i].name for i in range(len(model.layers))]\n",
    "# print summary\n",
    "model.summary()\n",
    "# train model\n",
    "history = model.fit(x_trace, y_trace, epochs=epochs, batch_size=batchsize, validation_split=validation_split, verbose=1)\n",
    "# save weights\n",
    "model.layers[model_names.index(\"discriminator_base\")].save_weights('weights/consecutive_discriminator_base_weights.h5')\n",
    "model.layers[model_names.index(\"discriminator_head\")].save_weights('weights/consecutive_discriminator_head_weights.h5')\n",
    "# save history\n",
    "pd.DataFrame(history.history, index=history.epoch, columns=history.history.keys()).to_hdf('history/consecutive_discriminator_history.h5', key=\"hist\")\n",
    "if RUNNING_IN_COLAB:\n",
    "    !cp -rf weights /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "    !cp -rf history /content/drive/MyDrive/DeepLearningFinalProject/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Train Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 700\n",
    "x_trace, y_trace, y_phase, y_amp, y_pileup = GetData()\n",
    "model = models.Model(inputs=input, outputs=phase_output)\n",
    "model.compile(optimizer=\"adam\", loss='mse', metrics=['accuracy'])\n",
    "model_names = [model.layers[i].name for i in range(len(model.layers))]\n",
    "model.layers[model_names.index(\"discriminator_base\")].load_weights('weights/consecutive_discriminator_base_weights.h5')\n",
    "model.layers[model_names.index(\"discriminator_head\")].load_weights('weights/consecutive_discriminator_head_weights.h5')\n",
    "model.layers[model_names.index(\"discriminator_base\")].trainable = False\n",
    "model.layers[model_names.index(\"discriminator_head\")].trainable = False\n",
    "# print summary\n",
    "model.summary()\n",
    "history = model.fit(x_trace, y_phase, epochs=epochs, batch_size=batchsize, validation_split=validation_split, verbose=1)\n",
    "# save weights\n",
    "model.layers[model_names.index(\"phase\")].save_weights('weights/consecutive_phase_weights.h5')\n",
    "# save history\n",
    "pd.DataFrame(history.history, index=history.epoch, columns=history.history.keys()).to_hdf('history/consecutive_phase_history.h5', key=\"hist\")\n",
    "if RUNNING_IN_COLAB:\n",
    "    !cp -rf weights /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "    !cp -rf history /content/drive/MyDrive/DeepLearningFinalProject/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 700\n",
    "x_trace, y_trace, y_phase, y_amp, y_pileup = GetData()\n",
    "model = models.Model(inputs=input, outputs=amplitude_output)\n",
    "model.compile(optimizer=\"adam\", loss='mse', metrics=['accuracy'])\n",
    "model_names = [model.layers[i].name for i in range(len(model.layers))]\n",
    "model.layers[model_names.index(\"discriminator_base\")].load_weights('weights/consecutive_discriminator_base_weights.h5')\n",
    "model.layers[model_names.index(\"discriminator_head\")].load_weights('weights/consecutive_discriminator_head_weights.h5')\n",
    "model.layers[model_names.index(\"discriminator_base\")].trainable = False\n",
    "model.layers[model_names.index(\"discriminator_head\")].trainable = False\n",
    "# print summary\n",
    "model.summary()\n",
    "history = model.fit(x_trace, y_amp, epochs=epochs, batch_size=batchsize, validation_split=validation_split, verbose=1)\n",
    "# save weights\n",
    "model.layers[model_names.index(\"amplitude\")].save_weights('weights/consecutive_amplitude_weights.h5')\n",
    "# save history\n",
    "pd.DataFrame(history.history, index=history.epoch, columns=history.history.keys()).to_hdf('history/consecutive_amplitude_history.h5', key=\"hist\")\n",
    "if RUNNING_IN_COLAB:\n",
    "    !cp -rf weights /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "    !cp -rf history /content/drive/MyDrive/DeepLearningFinalProject/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = layers.Input(shape=(1, 300))  # Returns a placeholder tensor\n",
    "discriminator_feature_vec = pn.TraceDiscriminatorBase(name = \"discriminator_base\")(input)\n",
    "trace_output = pn.TraceDiscriminatorHead(name = \"discriminator_head\")(discriminator_feature_vec)\n",
    "phase_output = pn.TracePhaseRegressor(name=\"phase\")(trace_output)\n",
    "amplitude_output = pn.TraceAmplitudeRegressor(name =\"amplitude\")(trace_output)\n",
    "\n",
    "model = models.Model(inputs=input, outputs=[trace_output, phase_output, amplitude_output])\n",
    "model.compile(optimizer=\"adam\", loss='mse', metrics=['accuracy'])\n",
    "model_names = [model.layers[i].name for i in range(len(model.layers))]\n",
    "model.layers[model_names.index(\"discriminator_base\")].load_weights('weights/consecutive_discriminator_base_weights.h5')\n",
    "model.layers[model_names.index(\"discriminator_head\")].load_weights('weights/consecutive_discriminator_head_weights.h5')\n",
    "model.layers[model_names.index(\"phase_regressor\")].load_weights('weights/consecutive_phase_weights.h5')\n",
    "model.layers[model_names.index(\"amplitude_regressor\")].load_weights('weights/consecutive_amplitude_weights.h5')\n",
    "\n",
    "# print summary\n",
    "model.summary()\n",
    "# save model\n",
    "model.save(\"models/consecutive_model.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
