{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Training__\n",
    "\n",
    "* ✅ **Sub-Modules**\n",
    "    * ✅ Discriminator\n",
    "    * ✅ Classifier\n",
    "    * ✅ Phase Regressor\n",
    "    * ✅ Amplitude Regressor\n",
    "\n",
    "\n",
    "* ✅ **Transfer Learning**\n",
    "    * ✅ Transfer 1 (Direct) \n",
    "        * ✅ Train Transfer Head on Trace, Phase and Amplitude\n",
    "        * ✅ Fine-Tune whole Model\n",
    "    * ✅ Transfer 2 (Long) \n",
    "        * ✅ Train Transfer Head on Trace\n",
    "        * ✅ Fine Tune Phase\n",
    "        * ✅ Fine Tune Amplitude\n",
    "\n",
    "\n",
    "* ✅ **Sequential Trianing** \n",
    "    * ✅ Train whole model on trace\n",
    "    * ✅ Train whole model on phase\n",
    "    * ✅ Train whole model on amplitude\n",
    "\n",
    "\n",
    "* ✅ **Control Training** \n",
    "    * ✅ Train whole model on trace, phase and amplitude\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in Colab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-14 01:31:00.586402: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-14 01:31:00.724375: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/tmengel/root/lib\n",
      "2023-05-14 01:31:00.724397: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-05-14 01:31:01.546409: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/tmengel/root/lib\n",
      "2023-05-14 01:31:01.546508: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/tmengel/root/lib\n",
      "2023-05-14 01:31:01.546517: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')   \n",
    "    RUNNING_IN_COLAB = True\n",
    "    \n",
    "except:\n",
    "    print(\"Not in Colab\")\n",
    "    RUNNING_IN_COLAB = False\n",
    "    \n",
    "if RUNNING_IN_COLAB:\n",
    "    print(\"Running in Colab\")\n",
    "    #pull git repo and install requirements\n",
    "    !git clone https://github.com/tmengel/Deep-Learning.git\n",
    "    %cd Deep-Learning/finalProject\n",
    "    %pip install uproot\n",
    "    %pip install pandas\n",
    "\n",
    "import pulsenet as pn\n",
    "import pandas as pd  \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"ysoTracesWithPileup.root\"\n",
    "if RUNNING_IN_COLAB:\n",
    "    filename = \"/content/drive/MyDrive/DeepLearningFinalProject/ysoTracesWithPileup.root\"\n",
    "    \n",
    "def GetData():\n",
    "    x_trace, y_trace, y_phase, y_amp = pn.CreateData(filename, pileup_split=0.5, phase_min=0.1, phase_max=20, amplitude_min=0.5, amplitude_max=1.5)\n",
    "    y_pileup = pn.EncodePileup(y_phase)\n",
    "    return x_trace, y_trace, y_phase, y_amp, y_pileup\n",
    "\n",
    "epochs = 500\n",
    "batchsize = 128 \n",
    "validation_split = 0.2\n",
    "\n",
    "def SaveModel(disriminator_base, classifier_base, phase, amplitude, tracenet, modelfile):\n",
    "    \n",
    "    input = layers.Input(shape=(1, 300))  # Returns a placeholder tensor\n",
    "    classifer_feature_vec = pn.TraceClassifierBase(name = \"classifier_base\")(input)\n",
    "    discriminator_feature_vec = pn.TraceDiscriminatorBase(name = \"discriminator_base\")(input)\n",
    "    trace_output = pn.TraceClassifierDiscriminatorHead(name = \"tracenet\")([discriminator_feature_vec, classifer_feature_vec])\n",
    "    phase_output = pn.TracePhaseRegressor(name=\"phase\")(trace_output)\n",
    "    amplitude_output = pn.TraceAmplitudeRegressor(name =\"amplitude\")(trace_output)\n",
    "    \n",
    "    model = models.Model(inputs=input, outputs=[trace_output, phase_output, amplitude_output])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "    model_names = [model.layers[i].name for i in range(len(model.layers))]\n",
    "    # load weights\n",
    "    model.layers[model_names.index(\"discriminator_base\")].load_weights(disriminator_base)\n",
    "    model.layers[model_names.index(\"classifier_base\")].load_weights(classifier_base)\n",
    "    model.layers[model_names.index(\"phase\")].load_weights(phase)\n",
    "    model.layers[model_names.index(\"amplitude\")].load_weights(amplitude)\n",
    "    model.layers[model_names.index(\"tracenet\")].load_weights(tracenet)\n",
    "    \n",
    "    # print summary\n",
    "    model.summary()\n",
    "    \n",
    "    # save model\n",
    "    model.save(modelfile)\n",
    "    \n",
    "    if RUNNING_IN_COLAB:\n",
    "        !cp models /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = layers.Input(shape=(1, 300))  # Returns a placeholder tensor\n",
    "classifer_feature_vec = pn.TraceClassifierBase(name = \"classifier_base\")(input)\n",
    "discriminator_feature_vec = pn.TraceDiscriminatorBase(name = \"discriminator_base\")(input)\n",
    "trace_output = pn.TraceClassifierDiscriminatorHead(name = \"tracenet\")([discriminator_feature_vec, classifer_feature_vec])\n",
    "\n",
    "x_trace, y_trace, y_phase, y_amp, y_pileup = GetData()\n",
    "# create model\n",
    "model = models.Model(inputs=input, outputs=trace_output)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "model_names = [model.layers[i].name for i in range(len(model.layers))]\n",
    "                          \n",
    "# print summary\n",
    "model.summary()                                                         \n",
    "# Train Discriminator Head\n",
    "history = model.fit(x_trace, y_trace, epochs=epochs, batch_size=batchsize, validation_split=validation_split, verbose=1)\n",
    "# save weights\n",
    "model.layers[model_names.index(\"discriminator_base\")].save_weights('weights/full_transfer_discriminator_base_weights_contingent.h5')\n",
    "model.layers[model_names.index(\"classifier_base\")].save_weights('weights/full_transfer_classifier_base_weights_contingent.h5')\n",
    "model.layers[model_names.index(\"tracenet\")].save_weights('weights/full_transfer_tracenet_weights_contingent.h5')\n",
    "\n",
    "# save history\n",
    "pd.DataFrame(history.history, index=history.epoch, columns=history.history.keys()).to_hdf('history/full_transfer_history_contingent.h5', key=\"hist\")\n",
    "# if RUNNING_IN_COLAB:\n",
    "!cp -rf weights /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "!cp -rf history /content/drive/MyDrive/DeepLearningFinalProject/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = layers.Input(shape=(1, 300))  # Returns a placeholder tensor\n",
    "classifer_feature_vec = pn.TraceClassifierBase(name = \"classifier_base\")(input)\n",
    "discriminator_feature_vec = pn.TraceDiscriminatorBase(name = \"discriminator_base\")(input)\n",
    "trace_output = pn.TraceClassifierDiscriminatorHead(name = \"tracenet\")([discriminator_feature_vec, classifer_feature_vec])\n",
    "phase_output = pn.TracePhaseRegressor(name=\"phase\")(trace_output)\n",
    "x_trace, y_trace, y_phase, y_amp, y_pileup = GetData()\n",
    "# create model\n",
    "model = models.Model(inputs=input, outputs=phase_output)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "model_names = [model.layers[i].name for i in range(len(model.layers))]\n",
    "# load weights\n",
    "model.layers[model_names.index(\"discriminator_base\")].load_weights('weights/full_transfer_discriminator_base_weights_contingent.h5')\n",
    "model.layers[model_names.index(\"classifier_base\")].load_weights('weights/full_transfer_classifier_base_weights_contingent.h5')\n",
    "model.layers[model_names.index(\"tracenet\")].load_weights('weights/full_transfer_tracenet_weights_contingent.h5')\n",
    "model.layers[model_names.index(\"discriminator_base\")].trainable = False\n",
    "model.layers[model_names.index(\"classifier_base\")].trainable = False\n",
    "model.layers[model_names.index(\"tracenet\")].trainable = False\n",
    "# print summary\n",
    "model.summary()                                                         \n",
    "# Train Discriminator Head\n",
    "history = model.fit(x_trace, y_phase, epochs=epochs, batch_size=batchsize, validation_split=validation_split, verbose=1)\n",
    "# save weights\n",
    "model.layers[model_names.index(\"phase\")].save_weights('weights/full_transfer_phase_weights_contingent.h5')\n",
    "\n",
    "pd.DataFrame(history.history, index=history.epoch, columns=history.history.keys()).to_hdf('history/full_transfer_phase_history_contingent.h5', key=\"hist\")\n",
    "# if RUNNING_IN_COLAB:\n",
    "!cp -rf weights /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "!cp -rf history /content/drive/MyDrive/DeepLearningFinalProject/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = layers.Input(shape=(1, 300))  # Returns a placeholder tensor\n",
    "classifer_feature_vec = pn.TraceClassifierBase(name = \"classifier_base\")(input)\n",
    "discriminator_feature_vec = pn.TraceDiscriminatorBase(name = \"discriminator_base\")(input)\n",
    "trace_output = pn.TraceClassifierDiscriminatorHead(name = \"tracenet\")([discriminator_feature_vec, classifer_feature_vec])\n",
    "amplitude_output = pn.TraceAmplitudeRegressor(name =\"amplitude\")(trace_output)\n",
    "\n",
    "x_trace, y_trace, y_phase, y_amp, y_pileup = GetData()\n",
    "# create model\n",
    "model = models.Model(inputs=input, outputs=amplitude_output)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "model_names = [model.layers[i].name for i in range(len(model.layers))]\n",
    "# load weights\n",
    "model.layers[model_names.index(\"discriminator_base\")].load_weights('weights/full_transfer_discriminator_base_weights_contingent.h5')\n",
    "model.layers[model_names.index(\"classifier_base\")].load_weights('weights/full_transfer_classifier_base_weights_contingent.h5')\n",
    "model.layers[model_names.index(\"tracenet\")].load_weights('weights/full_transfer_tracenet_weights_contingent.h5')\n",
    "model.layers[model_names.index(\"discriminator_base\")].trainable = False\n",
    "model.layers[model_names.index(\"classifier_base\")].trainable = False\n",
    "model.layers[model_names.index(\"tracenet\")].trainable = False\n",
    "                      \n",
    "# print summary\n",
    "model.summary()                                                         \n",
    "# Train Discriminator Head\n",
    "history = model.fit(x_trace, y_amp, epochs=epochs, batch_size=batchsize, validation_split=validation_split, verbose=1)\n",
    "# save weights\n",
    "model.layers[model_names.index(\"amplitude\")].save_weights('weights/full_transfer_amplitude_weights_contingent.h5')\n",
    "\n",
    "pd.DataFrame(history.history, index=history.epoch, columns=history.history.keys()).to_hdf('history/full_transfer_amplitude_history_contingent.h5', key=\"hist\")\n",
    "# if RUNNING_IN_COLAB:\n",
    "!cp -rf weights /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "!cp -rf history /content/drive/MyDrive/DeepLearningFinalProject/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Model(inputs=input, outputs=[trace_output, phase_output, amplitude_output])\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1, 300)]     0           []                               \n",
      "                                                                                                  \n",
      " discriminator_base (TraceDiscr  (None, 2, 300)      1893858     ['input_1[0][0]']                \n",
      " iminatorBase)                                                                                    \n",
      "                                                                                                  \n",
      " classifier_base (TraceClassifi  (None, 1, 300)      244456      ['input_1[0][0]']                \n",
      " erBase)                                                                                          \n",
      "                                                                                                  \n",
      " tracenet (TraceClassifierDiscr  (None, 2, 300)      631800      ['discriminator_base[0][0]',     \n",
      " iminatorHead)                                                    'classifier_base[0][0]']        \n",
      "                                                                                                  \n",
      " phase (TracePhaseRegressor)    (None, 1)            276149      ['tracenet[0][0]']               \n",
      "                                                                                                  \n",
      " amplitude (TraceAmplitudeRegre  (None, 1)           276149      ['tracenet[0][0]']               \n",
      " ssor)                                                                                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,322,412\n",
      "Trainable params: 3,322,412\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sub modules training**\n",
    "- ✅ Discrminator\n",
    "- ✅ Classifier\n",
    "- ✅ Phase \n",
    "- ✅ Amplitude"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Discriminator__ (Done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Data\n",
    "x_trace, y_trace, y_phase, y_amp, y_pileup = GetData()\n",
    "# Create model\n",
    "model = keras.Sequential([\n",
    "    pn.TraceDiscriminatorBase(name=\"discriminator_base\"),\n",
    "    pn.TraceDiscriminatorHead(name=\"discriminator_head\")\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(x_trace, y_trace, epochs=epochs, batch_size=batchsize, validation_split=validation_split, verbose=1)\n",
    "model.layers[0].save_weights('weights/individual_discriminator_base_weights.h5')\n",
    "model.layers[1].save_weights('weights/individual_discriminator_head_weights.h5')\n",
    "# Save history\n",
    "pd.DataFrame(history.history, index=history.epoch, columns=history.history.keys()).to_hdf('history/individual_discriminator_history.h5', key=\"hist\")\n",
    "\n",
    "if RUNNING_IN_COLAB:\n",
    "    !cp -rf weights /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "    !cp -rf history /content/drive/MyDrive/DeepLearningFinalProject/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Classifier__ (Done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trace, y_trace, y_phase, y_amp, y_pileup = GetData()\n",
    "# Create model\n",
    "model = keras.Sequential([\n",
    "    pn.TraceClassifierBase(name=\"classifier_base\"),\n",
    "    pn.TraceClassifierHead(name=\"classifier_head\")\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(x_trace, y_pileup, epochs=epochs, batch_size=batchsize, validation_split=validation_split, verbose=1)\n",
    "model.layers[0].save_weights('weights/individual_classifier_base_weights.h5')\n",
    "model.layers[1].save_weights('weights/individual_classifier_head_weights.h5')\n",
    "# Save history\n",
    "pd.DataFrame(history.history, index=history.epoch, columns=history.history.keys()).to_hdf('history/individual_classifier_history.h5', key=\"hist\")\n",
    "\n",
    "if RUNNING_IN_COLAB:\n",
    "    !cp -rf weights /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "    !cp -rf history /content/drive/MyDrive/DeepLearningFinalProject/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Amplitude__ (Done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trace, y_trace, y_phase, y_amp, y_pileup = GetData()\n",
    "# Create model\n",
    "model = keras.Sequential([\n",
    "    pn.TraceAmplitudeRegressor(name = \"amplitude\")\n",
    "])\n",
    "model.compile(optimizer='adam', loss=\"mse\", metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(x_trace, y_amp, epochs=epochs, batch_size=batchsize, validation_split=validation_split, verbose=1)\n",
    "model.layers[0].save_weights('weights/individual_amplitude_weights.h5')\n",
    "pd.DataFrame(history.history, index=history.epoch, columns=history.history.keys()).to_hdf('history/individual_amplitude_history.h5', key=\"hist\")\n",
    "\n",
    "if RUNNING_IN_COLAB:\n",
    "    !cp -rf weights /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "    !cp -rf history /content/drive/MyDrive/DeepLearningFinalProject/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Phase__ (Done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trace, y_trace, y_phase, y_amp, y_pileup = GetData()\n",
    "# Create model\n",
    "model = keras.Sequential([\n",
    "    pn.TracePhaseRegressor(name = \"phase\")\n",
    "])\n",
    "model.compile(optimizer='adam', loss=\"mse\", metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(x_trace, y_phase, epochs=epochs, batch_size=batchsize, validation_split=validation_split, verbose=1)\n",
    "model.layers[0].save_weights('weights/individual_phase_weights.h5')\n",
    "pd.DataFrame(history.history, index=history.epoch, columns=history.history.keys()).to_hdf('history/individual_phase_history.h5', key=\"hist\")\n",
    "\n",
    "if RUNNING_IN_COLAB:\n",
    "    !cp -rf weights /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "    !cp -rf history /content/drive/MyDrive/DeepLearningFinalProject/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **__Transfer Learning__**\n",
    "_____\n",
    "* ✅ Transfer 1 (Full)\n",
    "* ✅ Transfer 2 (Trace) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-14 01:29:07.914648: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/tmengel/root/lib\n",
      "2023-05-14 01:29:07.915640: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-05-14 01:29:07.915927: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tmengel): /proc/driver/nvidia/version does not exist\n",
      "2023-05-14 01:29:07.922093: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Exception encountered when calling layer \"phase\" (type TracePhaseRegressor).\n\nin user code:\n\n    File \"/home/tmengel/DeepLearning/Deep-Learning/finalProject/pulsenet.py\", line 301, in call  *\n        x = self.MaxPooling1D1(x)\n\n    AttributeError: 'TracePhaseRegressor' object has no attribute 'MaxPooling1D1'\n\n\nCall arguments received by layer \"phase\" (type TracePhaseRegressor):\n  • inputs=tf.Tensor(shape=(None, 2, 300), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/tmengel/DeepLearning/Deep-Learning/finalProject/training.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tmengel/DeepLearning/Deep-Learning/finalProject/training.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m discriminator_feature_vec \u001b[39m=\u001b[39m pn\u001b[39m.\u001b[39mTraceDiscriminatorBase(name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdiscriminator_base\u001b[39m\u001b[39m\"\u001b[39m)(\u001b[39minput\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tmengel/DeepLearning/Deep-Learning/finalProject/training.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m trace_output \u001b[39m=\u001b[39m pn\u001b[39m.\u001b[39mTraceClassifierDiscriminatorHead(name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtracenet\u001b[39m\u001b[39m\"\u001b[39m)([discriminator_feature_vec, classifer_feature_vec])\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tmengel/DeepLearning/Deep-Learning/finalProject/training.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m phase_output \u001b[39m=\u001b[39m pn\u001b[39m.\u001b[39;49mTracePhaseRegressor(name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mphase\u001b[39;49m\u001b[39m\"\u001b[39;49m)(trace_output)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tmengel/DeepLearning/Deep-Learning/finalProject/training.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m amplitude_output \u001b[39m=\u001b[39m pn\u001b[39m.\u001b[39mTraceAmplitudeRegressor(name \u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mamplitude\u001b[39m\u001b[39m\"\u001b[39m)(trace_output)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tmengel/DeepLearning/Deep-Learning/finalProject/training.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m classifier_output \u001b[39m=\u001b[39m pn\u001b[39m.\u001b[39mTraceClassifierHead(name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mclassifier_head\u001b[39m\u001b[39m\"\u001b[39m)(classifer_feature_vec)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileqqmmmn03.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m     10\u001b[0m x \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mConv1D1, (ag__\u001b[39m.\u001b[39mld(inputs),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 11\u001b[0m x \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mMaxPooling1D1, (ag__\u001b[39m.\u001b[39mld(x),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m x \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mFlatten, (ag__\u001b[39m.\u001b[39mld(x),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     13\u001b[0m x \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mDense1, (ag__\u001b[39m.\u001b[39mld(x),), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Exception encountered when calling layer \"phase\" (type TracePhaseRegressor).\n\nin user code:\n\n    File \"/home/tmengel/DeepLearning/Deep-Learning/finalProject/pulsenet.py\", line 301, in call  *\n        x = self.MaxPooling1D1(x)\n\n    AttributeError: 'TracePhaseRegressor' object has no attribute 'MaxPooling1D1'\n\n\nCall arguments received by layer \"phase\" (type TracePhaseRegressor):\n  • inputs=tf.Tensor(shape=(None, 2, 300), dtype=float32)"
     ]
    }
   ],
   "source": [
    "input = layers.Input(shape=(1, 300))  # Returns a placeholder tensor\n",
    "classifer_feature_vec = pn.TraceClassifierBase(name = \"classifier_base\")(input)\n",
    "discriminator_feature_vec = pn.TraceDiscriminatorBase(name = \"discriminator_base\")(input)\n",
    "trace_output = pn.TraceClassifierDiscriminatorHead(name = \"tracenet\")([discriminator_feature_vec, classifer_feature_vec])\n",
    "phase_output = pn.TracePhaseRegressor(name=\"phase\")(trace_output)\n",
    "amplitude_output = pn.TraceAmplitudeRegressor(name =\"amplitude\")(trace_output)\n",
    "classifier_output = pn.TraceClassifierHead(name=\"classifier_head\")(classifer_feature_vec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Transfer 1 (Direct)__ (Done)\n",
    "* ✅ Transfer trace, phase and classifier onto new head\n",
    "* ✅ Fine-tune model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trace, y_trace, y_phase, y_amp, y_pileup = GetData()\n",
    "# create model\n",
    "model = models.Model(inputs=input, outputs=[trace_output, phase_output, amplitude_output])\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "model_names = [model.layers[i].name for i in range(len(model.layers))]\n",
    "# load weights\n",
    "model.layers[model_names.index(\"discriminator_base\")].load_weights('weights/individual_discriminator_base_weights.h5')\n",
    "model.layers[model_names.index(\"classifier_base\")].load_weights('weights/individual_classifier_base_weights.h5')\n",
    "model.layers[model_names.index(\"phase\")].load_weights('weights/individual_phase_weights.h5')\n",
    "model.layers[model_names.index(\"amplitude\")].load_weights('weights/individual_amplitude_weights.h5')\n",
    "model.layers[model_names.index(\"discriminator_base\")].trainable = False\n",
    "model.layers[model_names.index(\"classifier_base\")].trainable = False\n",
    "model.layers[model_names.index(\"phase\")].trainable = False\n",
    "model.layers[model_names.index(\"amplitude\")].trainable = False                           \n",
    "# print summary\n",
    "model.summary()                                                         \n",
    "# Train Discriminator Head\n",
    "history = model.fit(x_trace, [y_trace, y_phase, y_amp], epochs=epochs, batch_size=batchsize, validation_split=validation_split, verbose=1)\n",
    "# save weights\n",
    "model.layers[model_names.index(\"tracenet\")].save_weights('weights/full_transfer_tracenet_weights.h5')\n",
    "# save model\n",
    "SaveModel(disciminator_base='weights/individual_discriminator_base_weights.h5',\n",
    "          classifier_base='weights/individual_classifier_base_weights.h5',\n",
    "          phase='weights/individual_phase_weights.h5',\n",
    "          amplitude='weights/individual_amplitude_weights.h5',\n",
    "          tracenet='weights/full_transfer_tracenet_weights.h5',\n",
    "          modelfile='models/full_transfer_model.h5')\n",
    "# save history\n",
    "pd.DataFrame(history.history, index=history.epoch, columns=history.history.keys()).to_hdf('history/full_transfer_history.h5', key=\"hist\")\n",
    "if RUNNING_IN_COLAB:\n",
    "    !cp -rf weights /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "    !cp -rf history /content/drive/MyDrive/DeepLearningFinalProject/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trace, y_trace, y_phase, y_amp, y_pileup = GetData()\n",
    "# create model\n",
    "model = models.Model(inputs=input, outputs=[trace_output, phase_output, amplitude_output])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=['mse', 'mse', 'mse'], metrics=['accuracy'])\n",
    "model_names = [model.layers[i].name for i in range(len(model.layers))]\n",
    "# load weights\n",
    "model.layers[model_names.index(\"discriminator_base\")].load_weights('weights/individual_discriminator_base_weights.h5')\n",
    "model.layers[model_names.index(\"classifier_base\")].load_weights('weights/individual_classifier_base_weights.h5')\n",
    "model.layers[model_names.index(\"phase\")].load_weights('weights/individual_phase_weights.h5')\n",
    "model.layers[model_names.index(\"amplitude\")].load_weights('weights/individual_amplitude_weights.h5')\n",
    "model.layers[model_names.index(\"tracenet\")].load_weights('weights/full_transfer_tracenet_weights.h5')                \n",
    "# print summary\n",
    "model.summary()                                                         \n",
    "# Train Discriminator Head\n",
    "history = model.fit(x_trace, [y_trace, y_phase, y_amp], epochs=epochs, batch_size=batchsize, validation_split=validation_split, verbose=1)\n",
    "# save weights\n",
    "model.layers[model_names.index(\"discriminator_base\")].save_weights('weights/full_transfer_fine_tuned_discriminator_base_weights.h5')\n",
    "model.layers[model_names.index(\"classifier_base\")].save_weights('weights/full_transfer_fine_tuned_classifier_base_weights.h5')\n",
    "model.layers[model_names.index(\"phase\")].save_weights('weights/full_transfer_fine_tuned_phase_weights.h5')\n",
    "model.layers[model_names.index(\"amplitude\")].save_weights('weights/full_transfer_fine_tuned_amplitude_weights.h5')\n",
    "model.layers[model_names.index(\"tracenet\")].save_weights('weights/full_transfer_fine_tuned_tracenet_weights.h5')\n",
    "# save model\n",
    "SaveModel(disciminator_base= 'weights/full_transfer_fine_tuned_discriminator_base_weights.h5',\n",
    "          classifier_base= 'weights/full_transfer_fine_tuned_classifier_base_weights.h5',\n",
    "          phase= 'weights/full_transfer_fine_tuned_phase_weights.h5',\n",
    "          amplitude= 'weights/full_transfer_fine_tuned_amplitude_weights.h5',\n",
    "          tracenet= 'weights/full_transfer_fine_tuned_tracenet_weights.h5',\n",
    "          modelfile='models/full_transfer_fine_tuned_model.h5')\n",
    "# save history\n",
    "pd.DataFrame(history.history, index=history.epoch, columns=history.history.keys()).to_hdf('history/full_transfer_fine_tuning_history.h5', key=\"hist\")\n",
    "if RUNNING_IN_COLAB:\n",
    "    !cp -rf weights /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "    !cp -rf history /content/drive/MyDrive/DeepLearningFinalProject/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Transfer 2 (Long)__ (Done)\n",
    "* ✅ Transfer Trace onto head\n",
    "* ✅ Transfer amplitude and phase onto head\n",
    "* ✅ Fine tune\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfer Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trace, y_trace, y_phase, y_amp, y_pileup = GetData()\n",
    "epochs = 200\n",
    "# create model\n",
    "model = models.Model(inputs=input, outputs=trace_output)\n",
    "model.compile(optimizer='adam', loss=\"mse\", metrics=['accuracy'])\n",
    "model_names = [model.layers[i].name for i in range(len(model.layers))]\n",
    "# load weights\n",
    "model.layers[model_names.index(\"discriminator_base\")].load_weights('weights/individual_discriminator_base_weights.h5')\n",
    "model.layers[model_names.index(\"classifier_base\")].load_weights('weights/individual_classifier_base_weights.h5')\n",
    "# freeze layers\n",
    "model.layers[model_names.index(\"discriminator_base\")].trainable = False\n",
    "model.layers[model_names.index(\"classifier_base\")].trainable = False                         \n",
    "# print summary\n",
    "model.summary()                                                         \n",
    "# Train Discriminator Head\n",
    "history = model.fit(x_trace,y_trace, epochs=epochs, batch_size=batchsize, validation_split=validation_split, verbose=1)\n",
    "# save weights\n",
    "model.layers[model_names.index(\"tracenet\")].save_weights('weights/trace_transfer_tracenet_weights.h5')\n",
    "# save model\n",
    "SaveModel(disciminator_base='weights/individual_discriminator_base_weights.h5',\n",
    "            classifier_base='weights/individual_classifier_base_weights.h5',\n",
    "            phase='weights/individual_phase_weights.h5',\n",
    "            amplitude='weights/individual_amplitude_weights.h5',\n",
    "            tracenet='weights/trace_transfer_tracenet_weights.h5',\n",
    "            modelfile='models/trace_transfer_model.h5')\n",
    "\n",
    "# save history\n",
    "pd.DataFrame(history.history, index=history.epoch, columns=history.history.keys()).to_hdf('history/trace_transfer_history.h5', key=\"hist\")\n",
    "if RUNNING_IN_COLAB:\n",
    "    !cp -rf weights /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "    !cp -rf history /content/drive/MyDrive/DeepLearningFinalProject/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine Tune Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trace, y_trace, y_phase, y_amp, y_pileup = GetData()\n",
    "epochs = 200\n",
    "# create model\n",
    "model = models.Model(inputs=input, outputs=phase_output)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=\"mse\", metrics=['accuracy'])\n",
    "model_names = [model.layers[i].name for i in range(len(model.layers))]\n",
    "# load weights\n",
    "model.layers[model_names.index(\"discriminator_base\")].load_weights('weights/individual_discriminator_base_weights.h5')\n",
    "model.layers[model_names.index(\"classifier_base\")].load_weights('weights/individual_classifier_base_weights.h5')\n",
    "model.layers[model_names.index(\"phase\")].load_weights('weights/individual_phase_weights.h5')\n",
    "model.layers[model_names.index(\"tracenet\")].load_weights('weights/trace_transfer_tracenet_weights.h5')\n",
    "# freeze layers\n",
    "model.layers[model_names.index(\"discriminator_base\")].trainable = False\n",
    "model.layers[model_names.index(\"classifier_base\")].trainable = False\n",
    "model.layers[model_names.index(\"tracenet\")].trainable = False\n",
    "# print summary\n",
    "model.summary()                                                         \n",
    "# Train Discriminator Head\n",
    "history = model.fit(x_trace, y_phase, epochs=epochs, batch_size=batchsize, validation_split=validation_split, verbose=1)\n",
    "# save weights\n",
    "model.layers[model_names.index(\"phase\")].save_weights('weights/trace_transfer_fine_tuned_phase_weights.h5')\n",
    "# save history\n",
    "pd.DataFrame(history.history, index=history.epoch, columns=history.history.keys()).to_hdf('history/trace_transfer_phase_fine_tuning_history.h5', key=\"hist\")\n",
    "if RUNNING_IN_COLAB:\n",
    "    !cp -rf weights /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "    !cp -rf history /content/drive/MyDrive/DeepLearningFinalProject/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Fine Tune Amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trace, y_trace, y_phase, y_amp, y_pileup = GetData()\n",
    "epochs = 200\n",
    "# create model\n",
    "model = models.Model(inputs=input, outputs=amplitude_output)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=\"mse\", metrics=['accuracy'])\n",
    "model_names = [model.layers[i].name for i in range(len(model.layers))]\n",
    "# load weights\n",
    "model.layers[model_names.index(\"discriminator_base\")].load_weights('weights/individual_discriminator_base_weights.h5')\n",
    "model.layers[model_names.index(\"classifier_base\")].load_weights('weights/individual_classifier_base_weights.h5')\n",
    "model.layers[model_names.index(\"amplitude\")].load_weights('weights/individual_amplitude_weights.h5')\n",
    "model.layers[model_names.index(\"tracenet\")].load_weights('weights/trace_transfer_tracenet_weights.h5')\n",
    "# freeze layers\n",
    "model.layers[model_names.index(\"discriminator_base\")].trainable = False\n",
    "model.layers[model_names.index(\"classifier_base\")].trainable = False\n",
    "model.layers[model_names.index(\"tracenet\")].trainable = False\n",
    "# print summary\n",
    "model.summary()                                                         \n",
    "# Train Discriminator Head\n",
    "history = model.fit(x_trace, y_amp, epochs=epochs, batch_size=batchsize, validation_split=validation_split, verbose=1)\n",
    "# save weights\n",
    "model.layers[model_names.index(\"amplitude\")].save_weights('weights/trace_transfer_fine_tuned_amplitude_weights.h5')\n",
    "# save history\n",
    "pd.DataFrame(history.history, index=history.epoch, columns=history.history.keys()).to_hdf('history/trace_transfer_amplitude_fine_tuning_history.h5', key=\"hist\")\n",
    "if RUNNING_IN_COLAB:\n",
    "    !cp -rf weights /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "    !cp -rf history /content/drive/MyDrive/DeepLearningFinalProject/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveModel(disciminator_base='weights/individual_discriminator_base_weights.h5',\n",
    "            classifier_base='weights/individual_classifier_base_weights.h5',\n",
    "            phase='weights/trace_transfer_fine_tuned_phase_weights.h5',\n",
    "            amplitude='weights/trace_transfer_fine_tuned_amplitude_weights.h5',\n",
    "            tracenet='weights/trace_transfer_tracenet_weights.h5',\n",
    "            modelfile='models/trace_transfer_fine_tuned_model.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Control__\n",
    "* ✅ Train whole network at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trace, y_trace, y_phase, y_amp, y_pileup = GetData()\n",
    "epochs = 1000\n",
    "# create model\n",
    "model = models.Model(inputs=input, outputs=[trace_output, phase_output, amplitude_output])\n",
    "model.compile(optimizer=\"adam\",loss=\"mse\", metrics=['accuracy'])\n",
    "model_names = [model.layers[i].name for i in range(len(model.layers))]\n",
    "# print summary\n",
    "model.summary()\n",
    "# train control model\n",
    "history = model.fit(x_trace, [y_trace, y_phase, y_amp], epochs=epochs, batch_size=batchsize, validation_split=validation_split, verbose=1)\n",
    "# save weights\n",
    "model.layers[model_names.index(\"discriminator_base\")].save_weights('weights/control_discriminator_base_weights.h5')\n",
    "model.layers[model_names.index(\"classifier_base\")].save_weights('weights/control_classifier_base_weights.h5')\n",
    "model.layers[model_names.index(\"phase\")].save_weights('weights/control_phase_weights.h5')\n",
    "model.layers[model_names.index(\"amplitude\")].save_weights('weights/control_amplitude_weights.h5')\n",
    "model.layers[model_names.index(\"tracenet\")].save_weights('weights/control_tracenet_weights.h5')\n",
    "# save model\n",
    "SaveModel(disciminator_base='weights/control_discriminator_base_weights.h5',\n",
    "            classifier_base='weights/control_classifier_base_weights.h5',\n",
    "            phase='weights/control_phase_weights.h5',\n",
    "            amplitude='weights/control_amplitude_weights.h5',\n",
    "            tracenet='weights/control_tracenet_weights.h5',\n",
    "            modelfile='models/control_model.h5')\n",
    "\n",
    "# save history\n",
    "pd.DataFrame(history.history, index=history.epoch, columns=history.history.keys()).to_hdf('history/control_history.h5', key=\"hist\")\n",
    "if RUNNING_IN_COLAB:\n",
    "    !cp -rf weights /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "    !cp -rf history /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Sequential Training__\n",
    "* ✅ Train whole model on trace\n",
    "* ✅ Train whole model on phase\n",
    "* ✅ Train whole model on amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = layers.Input(shape=(1, 300))  # Returns a placeholder tensor\n",
    "discriminator_feature_vec = pn.TraceDiscriminatorBase(name = \"discriminator_base\")(input)\n",
    "trace_output = pn.TraceDiscriminatorHead(name = \"discriminator_head\")(discriminator_feature_vec)\n",
    "phase_output = pn.TracePhaseRegressor(name=\"phase\")(trace_output)\n",
    "amplitude_output = pn.TraceAmplitudeRegressor(name =\"amplitude\")(trace_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Train Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load new data\n",
    "epochs = 700\n",
    "x_trace, y_trace, y_phase, y_amp, y_pileup = GetData()\n",
    "\n",
    "# Train Discriminator\n",
    "# create model\n",
    "model = models.Model(inputs=input, outputs=trace_output)\n",
    "model.compile(optimizer=\"adam\", loss='mse', metrics=['accuracy'])\n",
    "model_names = [model.layers[i].name for i in range(len(model.layers))]\n",
    "# print summary\n",
    "model.summary()\n",
    "# train model\n",
    "history = model.fit(x_trace, y_trace, epochs=epochs, batch_size=batchsize, validation_split=validation_split, verbose=1)\n",
    "# save weights\n",
    "model.layers[model_names.index(\"discriminator_base\")].save_weights('weights/consecutive_discriminator_base_weights.h5')\n",
    "model.layers[model_names.index(\"discriminator_head\")].save_weights('weights/consecutive_discriminator_head_weights.h5')\n",
    "# save history\n",
    "pd.DataFrame(history.history, index=history.epoch, columns=history.history.keys()).to_hdf('history/consecutive_discriminator_history.h5', key=\"hist\")\n",
    "if RUNNING_IN_COLAB:\n",
    "    !cp -rf weights /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "    !cp -rf history /content/drive/MyDrive/DeepLearningFinalProject/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Train Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 700\n",
    "x_trace, y_trace, y_phase, y_amp, y_pileup = GetData()\n",
    "model = models.Model(inputs=input, outputs=phase_output)\n",
    "model.compile(optimizer=\"adam\", loss='mse', metrics=['accuracy'])\n",
    "model_names = [model.layers[i].name for i in range(len(model.layers))]\n",
    "model.layers[model_names.index(\"discriminator_base\")].load_weights('weights/consecutive_discriminator_base_weights.h5')\n",
    "model.layers[model_names.index(\"discriminator_head\")].load_weights('weights/consecutive_discriminator_head_weights.h5')\n",
    "model.layers[model_names.index(\"discriminator_base\")].trainable = False\n",
    "model.layers[model_names.index(\"discriminator_head\")].trainable = False\n",
    "# print summary\n",
    "model.summary()\n",
    "history = model.fit(x_trace, y_phase, epochs=epochs, batch_size=batchsize, validation_split=validation_split, verbose=1)\n",
    "# save weights\n",
    "model.layers[model_names.index(\"phase\")].save_weights('weights/consecutive_phase_weights.h5')\n",
    "# save history\n",
    "pd.DataFrame(history.history, index=history.epoch, columns=history.history.keys()).to_hdf('history/consecutive_phase_history.h5', key=\"hist\")\n",
    "if RUNNING_IN_COLAB:\n",
    "    !cp -rf weights /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "    !cp -rf history /content/drive/MyDrive/DeepLearningFinalProject/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 700\n",
    "x_trace, y_trace, y_phase, y_amp, y_pileup = GetData()\n",
    "model = models.Model(inputs=input, outputs=amplitude_output)\n",
    "model.compile(optimizer=\"adam\", loss='mse', metrics=['accuracy'])\n",
    "model_names = [model.layers[i].name for i in range(len(model.layers))]\n",
    "model.layers[model_names.index(\"discriminator_base\")].load_weights('weights/consecutive_discriminator_base_weights.h5')\n",
    "model.layers[model_names.index(\"discriminator_head\")].load_weights('weights/consecutive_discriminator_head_weights.h5')\n",
    "model.layers[model_names.index(\"discriminator_base\")].trainable = False\n",
    "model.layers[model_names.index(\"discriminator_head\")].trainable = False\n",
    "# print summary\n",
    "model.summary()\n",
    "history = model.fit(x_trace, y_amp, epochs=epochs, batch_size=batchsize, validation_split=validation_split, verbose=1)\n",
    "# save weights\n",
    "model.layers[model_names.index(\"amplitude\")].save_weights('weights/consecutive_amplitude_weights.h5')\n",
    "# save history\n",
    "pd.DataFrame(history.history, index=history.epoch, columns=history.history.keys()).to_hdf('history/consecutive_amplitude_history.h5', key=\"hist\")\n",
    "if RUNNING_IN_COLAB:\n",
    "    !cp -rf weights /content/drive/MyDrive/DeepLearningFinalProject/\n",
    "    !cp -rf history /content/drive/MyDrive/DeepLearningFinalProject/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = layers.Input(shape=(1, 300))  # Returns a placeholder tensor\n",
    "discriminator_feature_vec = pn.TraceDiscriminatorBase(name = \"discriminator_base\")(input)\n",
    "trace_output = pn.TraceDiscriminatorHead(name = \"discriminator_head\")(discriminator_feature_vec)\n",
    "phase_output = pn.TracePhaseRegressor(name=\"phase\")(trace_output)\n",
    "amplitude_output = pn.TraceAmplitudeRegressor(name =\"amplitude\")(trace_output)\n",
    "\n",
    "model = models.Model(inputs=input, outputs=[trace_output, phase_output, amplitude_output])\n",
    "model.compile(optimizer=\"adam\", loss='mse', metrics=['accuracy'])\n",
    "model_names = [model.layers[i].name for i in range(len(model.layers))]\n",
    "model.layers[model_names.index(\"discriminator_base\")].load_weights('weights/consecutive_discriminator_base_weights.h5')\n",
    "model.layers[model_names.index(\"discriminator_head\")].load_weights('weights/consecutive_discriminator_head_weights.h5')\n",
    "model.layers[model_names.index(\"phase_regressor\")].load_weights('weights/consecutive_phase_weights.h5')\n",
    "model.layers[model_names.index(\"amplitude_regressor\")].load_weights('weights/consecutive_amplitude_weights.h5')\n",
    "\n",
    "# print summary\n",
    "model.summary()\n",
    "# save model\n",
    "model.save(\"models/consecutive_model.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
